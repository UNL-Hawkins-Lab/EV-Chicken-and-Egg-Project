{
 "cells": [
  {
   "cell_type": "raw",
   "id": "01823faf",
   "metadata": {},
   "source": [
    "---\n",
    "title: On the Chicken & Egg Problem in Transportation Electrification\n",
    "author: Jason Hawkins\n",
    "format: pdf\n",
    "editor: visual\n",
    "echo: false\n",
    "number-sections: true\n",
    "keep-tex: true\n",
    "bibliography: references.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7afce",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Vehicle electrification is widely regarded as a critical tool for climate change mitigation in the transportation sector [@musti2011]. While the United States is seeing an increasing share of electric sales, the pace of adoption remains well below the necessary level to mitigate climate change impacts. One barrier to widespread adoption is the lack of charging infrastructure [@sullivan2021].\n",
    "\n",
    "A common policy put forward to increase electric vehicle adoption is a federal income tax credit for EV buyers. However, spending similar amounts on increasing deployment of charging stations could yield more effective results [@Li2017]. This is especially the case in the early stages of EV market penetration; EV markets that have critical-mass constraints have the most success in increasing market penetration with a subsidy policy that deals with indirect network effects [@Zhou2018]. One of the indirect network effects on the EV market comes from the charging station market.\n",
    "\n",
    "Subsidies for charging stations are found to be most effective because of the low-price sensitivity of early EV adopters [@Li2017]. This is intuitive because early EV adopters are more eager to purchases EVs, which makes them more willing to pay for higher prices. The issue these consumers are concerned with is their ability to utilize this new technology, which is affected by the existing charging station infrastructure. Because of this, understanding consumerâ€™s preferences for charging station infrastructure is crucial. Consumers are willing to pay about 5 cents per mile for plug-in electric vehicles and about 10 cents per minute of wait time while refueling. Consumers are also willing to wait up to 8 minutes longer during refueling [@Sheldon2019]. Knowing this information can allow policy makers to create subsidy programs that produce more effective outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400098b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplot as gplt\n",
    "import geopandas as gpd\n",
    "import geoplot.crs as gcrs\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mapclassify as mc\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "#from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "#pysqldf = lambda q: sqldf(q, globals())\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "warnings.simplefilter(action='once', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583f2cc",
   "metadata": {},
   "source": [
    "# The Electric Vehicle and Charging Station Problem\n",
    "\n",
    "Electric vehicle ownership is often referenced as exhibiting a \"chicken and egg\" behavior arising from the supply and demand relationship. Individual demand for electric vehicles is influenced by the available supply of charging points. Consumers are unwilling to purchase vehicles due to range anxiety and a perceived lack of charging stations. Suppliers are not incentivized to provide charging stations unless there is sufficient demand to warrant their cost. There is a clear role for public policy in such situations. The government deems electric vehicles as a solution to a public ill (i.e., climate change) and can incentivize either suppliers by providing installation subsidies or consumers by installing charging stations. While the problem has been recognized in the literature [@melliger2018], empirical analysis is minimal.\n",
    "\n",
    "An important consideration to the analysis is how electric mobility system may differ from one based on fossil fuels. In the conventional private mobility model, the individual owns the vehicle and purchases fuel from centralized and privately owned refueling stations. In contrast, electric vehicles may be charged in the home using previously existing infrastructure. The presence of charging points in the home begs the questions 1) if (or to what extent) out-of-home charging stations are required for travel? and 2) to what extent is range anxiety a perception versus a reality?\n",
    "\n",
    "According to the Bureau of Transportation Statistics, 98% of trips made in the US are less than 50 miles [@vehicletechnologyoffice2022]. Given that most battery-electric vehicles (BEVs) have a range greater than 200 miles [@elfalan2021], it is feasible to make most trips on a single charge. However, long-distance trips (over 50 miles) comprise 30% of total vehicle-miles traveled (VMT) [@aultman-hall2018]. There is clearly a need for out-of-home charging stations to accommodate these trips. Even if most trips can be accommodated by in-home charging, the vehicle purchase decision will be influenced by consideration of these longer trips that require charging stations [@silvia2016]. Additionally, Wolbertus et al. [@wolbertus2018] find that there is still a demand for charging stations in places where public daytime charging is the only option, such as at the workplace.\n",
    "\n",
    "# Data Sources\n",
    "\n",
    "We use a combination of open-source and purchased data in our analysis. The two key input datasets are charging station locations provided by the Alternative Fuel Data Center (AFDC) and electric vehicle registrations provided by Experian Inc. The vehicle registration dataset comprises a 10-year panel at 2-year increments (2012, 2014, 2016, 2018, 2020). Total vehicle registrations are recorded by county, make, model, year, and other vehicle characteristics for the United States.\n",
    "\n",
    "After filtering out protectorates and other state-state locations, several county codes in the Experian data remain that are missing registration totals in a subsset of years (192/3172, or about 6%). We remove county codes with more than one missing year, leaving 186 for which registration totals are interpolated from adjacent years. Many of these county codes are for remote areas with low populations (e.g., the Aleutian Islands in Alaska and much of Idaho)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae4679-afd4-4c10-b782-91812c6e4d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  https://gist.github.com/rogerallen/1583593\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112174e0-00ca-42fa-b3f0-1843a5e0043a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_veh_regs(df):\n",
    "    geo_ct = df.GEOID.value_counts()==4\n",
    "    cty_list = list(np.unique(df[df.GEOID.isin(geo_ct[geo_ct].index)].GEOID.values)) # record count is 4 for the county\n",
    "    yr_set = set([2012,2014,2016,2018,2020])\n",
    "    for cty in cty_list:\n",
    "        temp = df[df.GEOID==cty]\n",
    "        miss_yr = (yr_set-set(temp.year)).pop()\n",
    "        row = temp.iloc[0].copy() # initialize new row to the first row in dataset\n",
    "        row.loc[\"year\"] = miss_yr\n",
    "        if(miss_yr==2012):\n",
    "            row[~row.index.isin([\"GEOID\",\"year\"])] = np.reshape(temp.loc[temp.year==2014,~temp.columns.isin([\"GEOID\",\"year\"])].values - (temp.loc[temp.year==2016,~temp.columns.isin([\"GEOID\",\"year\"])].values - temp.loc[temp.year==2014,~temp.columns.isin([\"GEOID\",\"year\"])].values),-1)\n",
    "        elif(miss_yr==2020):\n",
    "            row[~row.index.isin([\"GEOID\",\"year\"])] = np.reshape(temp.loc[temp.year==2018,~temp.columns.isin([\"GEOID\",\"year\"])].values + (temp.loc[temp.year==2018,~temp.columns.isin([\"GEOID\",\"year\"])].values - temp.loc[temp.year==2016,~temp.columns.isin([\"GEOID\",\"year\"])].values),-1)\n",
    "        else:\n",
    "            row[~row.index.isin([\"GEOID\",\"year\"])] = np.reshape((temp.loc[temp.year==(miss_yr+2),~temp.columns.isin([\"GEOID\",\"year\"])].values + temp.loc[temp.year==(miss_yr-2),~temp.columns.isin([\"GEOID\",\"year\"])].values)/2,-1)                                       \n",
    "        df = pd.concat((df,row.to_frame().T),ignore_index=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a023efc-b494-4731-993b-01776712c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_station_lags(df, id_col, yr_col, ch_col):\n",
    "    cty_list = np.unique(df[:,id_col])\n",
    "    for cty in cty_list:\n",
    "        temp = df[df[:,id_col]==cty]\n",
    "        yr_list = temp[:,yr_col]\n",
    "        yr_set = set(yr_list)\n",
    "        i = 0\n",
    "        for yr in range(2012,2021,1):\n",
    "            if(yr>np.min(yr_list)): # if the year is after the first installation year (prior years will be autofilled as zero when merged with registration data)\n",
    "                if(yr not in yr_list): # if the year isn't in the list of years for the county\n",
    "                    row = temp[i].copy()\n",
    "                    row[yr_col] = yr\n",
    "                    row[ch_col:ch_col+2] = 0 # no stations installed in this year\n",
    "                    row_mat = row[np.newaxis]\n",
    "                    df = np.vstack((df,row_mat))\n",
    "                else:\n",
    "                    i+=1 # update previous row id if the year is in temp df\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0039795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load county shapefile\n",
    "US_sf = gpd.read_file(\"../Data/GIS/cb_2018_us_county_5m/cb_2018_us_county_5m.shp\")\n",
    "#Removing the outlying islands and other territories. \n",
    "US_sf[\"STATEFP\"] =pd.to_numeric(US_sf[\"STATEFP\"])\n",
    "US_sf = US_sf[US_sf['STATEFP'] < 57]\n",
    "US_sf = US_sf.to_crs(2163)\n",
    "\n",
    "# load in state population totals\n",
    "df_pop = pd.read_csv(\"../Data/Census/PopByState/state_pop_est_2019.csv\")\n",
    "df_pop['State'] = df_pop['Geographic Area'].map(us_state_to_abbrev)\n",
    "\n",
    "# load charging station data\n",
    "df_ch_stn = pd.read_csv(\"../Data/Transport/alt_fuel_stations_w_county.csv\")\n",
    "print(\"df_ch_stn all\",df_ch_stn.shape[0])\n",
    "print(\"df_ch_stn no private\",df_ch_stn.shape[0])\n",
    "df_ch_stn = df_ch_stn[pd.notnull(df_ch_stn[\"Open Date\"])]\n",
    "print(\"df_ch_stn (after removing nan open year\",df_ch_stn.shape[0])\n",
    "df_ch_stn = df_ch_stn.assign(year=pd.to_datetime(df_ch_stn.loc[:,'Open Date']).dt.year.astype(int))\n",
    "df_ch_stn = df_ch_stn.drop(columns=\"Open Date\")\n",
    "df_ch_stn = df_ch_stn[df_ch_stn.STATEFP<=56]\n",
    "id_col = df_ch_stn.columns.get_loc(\"GEOID\")\n",
    "yr_col = df_ch_stn.columns.get_loc(\"year\")\n",
    "ch_col = df_ch_stn.columns.get_loc(\"EVSE-L01\")\n",
    "df_ch_stn = pd.DataFrame(data=fill_station_lags(df_ch_stn.values, id_col, yr_col,ch_col), columns=df_ch_stn.columns)\n",
    "geometry = [Point(xy) for xy in zip(df_ch_stn.Longitude, df_ch_stn.Latitude)]\n",
    "crs = {'init' :'epsg:2163'}\n",
    "geo_ch_stn = gpd.GeoDataFrame(df_ch_stn, crs=crs, geometry=geometry)\n",
    "geo_ch_stn = gpd.sjoin(geo_ch_stn, US_sf, how='left', predicate='within')\n",
    "grp_ch_stn = df_ch_stn.groupby([\"GEOID\",\"year\"]).sum()[[\"EVSE-L01\",\"EVSE-L02\",\"EVSE-L03\"]].reset_index()\n",
    "grp_ch_stn[\"cEVSE-L01\"]=grp_ch_stn[[\"GEOID\",\"EVSE-L01\"]].groupby(\"GEOID\").cumsum()\n",
    "grp_ch_stn[\"cEVSE-L02\"]=grp_ch_stn[[\"GEOID\",\"EVSE-L02\"]].groupby(\"GEOID\").cumsum()\n",
    "grp_ch_stn[\"cEVSE-L03\"]=grp_ch_stn[[\"GEOID\",\"EVSE-L03\"]].groupby(\"GEOID\").cumsum()\n",
    "grp_ch_stn[\"cEVSE\"]=grp_ch_stn[\"cEVSE-L01\"]+grp_ch_stn[\"cEVSE-L02\"]+grp_ch_stn[\"cEVSE-L03\"]\n",
    "\n",
    "# load vehicle registrations data\n",
    "df_veh_reg = pd.read_parquet(\"../Data/Transport/Experian Registrations/sum_registrations.parquet\")\n",
    "# fill nan with zero and aggregate electricity columns\n",
    "df_veh_reg.fillna(0, inplace=True)\n",
    "df_veh_reg = impute_veh_regs(df_veh_reg)\n",
    "df_veh_reg = df_veh_reg.assign(bev=df_veh_reg[\"24kw Electric~Electric\"]+df_veh_reg[\"60kw Electric~Electric\"]+df_veh_reg[\"85kw Electric~Electric\"]+df_veh_reg[\"90kw Electric~Electric\"]+df_veh_reg[\"Electric\"]+df_veh_reg[\"Electric Fuel System\"])\n",
    "df_veh_reg = df_veh_reg.assign(pev=(df_veh_reg[\"bev\"]+df_veh_reg[\"Plug-In Hybrid\"]))\n",
    "# percent bev is bev/total vehicles\n",
    "df_veh_reg = df_veh_reg.assign(per_bev=df_veh_reg[\"bev\"] / df_veh_reg[\"All\"])\n",
    "# percent pev is (bev+phev)/total vehicles\n",
    "df_veh_reg = df_veh_reg.assign(per_pev=df_veh_reg[\"pev\"] / df_veh_reg[\"All\"])\n",
    "\n",
    "# combine registration and charging data by year and county code\n",
    "df = df_veh_reg.merge(grp_ch_stn.loc[:,[\"GEOID\",\"year\",\"cEVSE-L01\",\"cEVSE-L02\",\"cEVSE-L03\",\"cEVSE\"]],how=\"left\",left_on=[\"GEOID\",\"year\"],right_on=[\"GEOID\",\"year\"])\n",
    "# add additional columns for lagged charging station counts\n",
    "df[\"lag_year\"] = df.year-1\n",
    "df = df.merge(grp_ch_stn.loc[:,[\"GEOID\",\"year\",\"cEVSE-L01\",\"cEVSE-L02\",\"cEVSE-L03\",\"cEVSE\"]],how=\"left\",left_on=[\"GEOID\",\"lag_year\"],right_on=[\"GEOID\",\"year\"],suffixes=(\"\",\"_lag\"))\n",
    "df[\"GEOID\"] = df[\"GEOID\"].astype(int)\n",
    "\n",
    "# read in demographic data by county and add to main dataframe\n",
    "df_pop11 = pd.read_csv(\"../Data/Census/county_pop_race_age_2011_2015.csv\")\n",
    "df_pop15 = pd.read_csv(\"../Data/Census/county_pop_race_age_2015_2019.csv\")\n",
    "\n",
    "# read in egrid data and add to main dataframe\n",
    "\n",
    "# join demographics to main dataframe for 2011 to 2015\n",
    "df11 = df.loc[df.year<2015,:].merge(df_pop11, how=\"left\", left_on=\"GEOID\", right_on=\"GEOID\")\n",
    "# update data for years 2015 forward to use the 2015-2019 data\n",
    "df15 = df.loc[df.year>=2015,:].merge(df_pop15, how=\"left\", left_on=\"GEOID\", right_on=\"GEOID\")\n",
    "df = pd.concat((df11,df15),axis=0)\n",
    "# some data are assigned county codes that don't appear in the population dataset. They should be removed for analysis.\n",
    "df.dropna(axis=0,subset=\"ALUBE001\", inplace=True)\n",
    "\n",
    "# calculate per capita statistics (per 100,000 inhabitants)\n",
    "df[\"bev_cap\"] = (df[\"bev\"]/df[\"ALUBE001\"])*100000\n",
    "df[\"pev_cap\"] = (df[\"pev\"]/df[\"ALUBE001\"])*100000\n",
    "df[\"cEVSE-L01_cap\"] = (df[\"cEVSE-L01\"]/df[\"ALUBE001\"])*100000\n",
    "df[\"cEVSE_L02_cap\"] = (df[\"cEVSE-L02\"]/df[\"ALUBE001\"])*100000\n",
    "df[\"cEVSE_L03_cap\"] = (df[\"cEVSE-L03\"]/df[\"ALUBE001\"])*100000\n",
    "df[\"cEVSE_cap\"] = (df[\"cEVSE\"]/df[\"ALUBE001\"])*100000\n",
    "df[\"cEVSE_cap_lag\"] = (df[\"cEVSE_lag\"]/df[\"ALUBE001\"])*100000\n",
    "\n",
    "#df.fillna(0,inplace=True) # careful using a blanket fillna statement on a dataframe\n",
    "df.sort_values(by=[\"GEOID\",\"year\"],inplace=True)\n",
    "temp = df.GEOID.value_counts()==5 # data available for all years. Some remote areas and reservations do not have data available for all years\n",
    "df = df[df.GEOID.isin(temp[temp].index.get_level_values(0).values)]\n",
    "\n",
    "# additional data from GIS file for county\n",
    "US_sf[\"GEOID\"] = US_sf[\"GEOID\"].astype(int)\n",
    "gdf = US_sf.merge(df, how=\"right\", on=\"GEOID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e5a64-0af0-411b-ad76-7d1756589205",
   "metadata": {},
   "source": [
    "To capture spatial spillover effects, a Queen contiguity matrix is constructed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3218ea-a608-405d-a534-e3db54f3cd7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO DO: Add model variables, Create a summary statistics table\n",
    "from libpysal.weights import Queen\n",
    "w_queen = Queen.from_dataframe(gdf)\n",
    "gdf[\"xW\"] = w_queen.sparse*gdf.cEVSE_cap.values\n",
    "\n",
    "# add state FE\n",
    "gdf = pd.concat([gdf,pd.get_dummies(gdf.STATEA, prefix=\"st_\", drop_first=True)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0d9eb-bc2d-4643-947f-b1d36a9c3f4f",
   "metadata": {},
   "source": [
    "# Results\n",
    "@us-totals provides a first validation of the research hypothesis. Registered plugin electric vehicles (PEVs) and public charging stations are normalized by population and plotted over the eight year analysis period for the United States. The two infrastructure show a similar exponential increase, suggesting there is a correlation between their adoption but giving no indication of temporal phasing or causality.\n",
    "\n",
    "The classical Granger causality test assumes stationary data, which is not the case here based on visual inspection and confirmed by ADF and KPSS tests. Several non-linear extensions to Granger causality have been developed in recent years (REF). One challenge applying such methods to our application is that non-linear methods require a larger time series than the five annual totals purchased from Experian. We address this limitation by leveraging the multiple observations available in each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa458d-1ce4-44e6-943f-edd411c176fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # check matrix calculation by hand\n",
    "# w_queen = Queen.from_dataframe(gdf[0:10])\n",
    "# xW = w_queen.sparse*gdf[0:10].cEVSE_cap.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ac110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| layout-ncol: 1\n",
    "#| label: us-totals\n",
    "#| fig-cap: \"US BEV Registrations and Charging Stations\"\n",
    "plt.style.use('seaborn-white')\n",
    "us_tot = df.groupby(\"year\").sum().reset_index()\n",
    "us_tot[\"pev_cap\"] = (us_tot[\"pev\"]/us_tot[\"ALUBE001\"])*100000\n",
    "us_tot[\"cEVSE_cap\"] = ((us_tot[\"cEVSE-L01\"]+us_tot[\"cEVSE-L02\"]+us_tot[\"cEVSE-L03\"])/us_tot[\"ALUBE001\"])*100000\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = us_tot.year\n",
    "y1 = us_tot.bev_cap\n",
    "y2 = us_tot.cEVSE_cap\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ln1 = ax.plot(x, y1, '-b', label='PEVs')\n",
    "ln2 = ax2.plot(x,y2, '--r', label=\"Charging stations\")\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('PEVs (per 100,000 persons)')\n",
    "ax2.set_ylabel('Charging stations (per 100,000 persons)')\n",
    "ax2.grid(False)\n",
    "lns = ln1+ln2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc='upper left', frameon=True);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3633cca-817e-40c3-89a8-480ff3e75184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(seed=98765)\n",
    "plt.style.use('seaborn-white')\n",
    "GEOID_list = np.random.choice(pd.unique(df.GEOID),size=5,replace=False)\n",
    "sub_df = df[df.GEOID.isin(GEOID_list)]\n",
    "sub_df = sub_df.groupby([\"GEOID\",\"year\"]).sum().reset_index()\n",
    "sub_df[\"pev_cap\"] = (sub_df[\"pev\"]/sub_df[\"ALUBE001\"])*100000\n",
    "sub_df[\"cEVSE_cap\"] = ((sub_df[\"cEVSE-L01\"]+sub_df[\"cEVSE-L02\"]+sub_df[\"cEVSE-L03\"])/sub_df[\"ALUBE001\"])*100000\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, j in enumerate(GEOID_list):\n",
    "    x = sub_df[sub_df.GEOID==j].year+i*9\n",
    "    y1 = sub_df[sub_df.GEOID==j].bev_cap\n",
    "    y2 = sub_df[sub_df.GEOID==j].cEVSE_cap\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    ax2.axes.yaxis.set_visible(False)\n",
    "    if i==0:\n",
    "        ln1 = ax.plot(x, y1, '-b', label='PEVs')\n",
    "        ln2 = ax2.plot(x,y2, '--r', label=\"Charging stations\")\n",
    "        ax2.grid(False)\n",
    "        #lns = ln1+ln2\n",
    "        #labs = [l.get_label() for l in lns]   \n",
    "    else:\n",
    "        ax.plot(x, y1, '-b', label='PEVs')\n",
    "        ax2.plot(x,y2, '--r', label=\"Charging stations\")\n",
    "    ax.annotate('County {0}'.format(i+1), \n",
    "             xy=(0.05+i*0.2, -0.1), # these are the coordinates to position the label\n",
    "             xycoords='axes fraction') # you can pass any extra params too\n",
    "        \n",
    "ax.legend(lns, labs, loc='upper left', frameon=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9f4b5-c307-42a5-ac32-e0b05e4a36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOID_list = np.random.choice(pd.unique(df.GEOID),size=5,replace=False)\n",
    "GEOID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5887dd6-7437-41a3-8f52-35e49a56aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhawkins17\\AppData\\Local\\Temp\\ipykernel_15356\\2280335719.py:1: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  check14c = pd.read_csv(\"../Data/Transport/Experian Registrations/US_EVD_Fleet_LD_COUNTY_NC-WY_2014Q4.csv\")\n"
     ]
    }
   ],
   "source": [
    "check14c = pd.read_csv(\"../Data/Transport/Experian Registrations/US_EVD_Fleet_LD_COUNTY_NC-WY_2014Q4.csv\")\n",
    "check14p = pd.read_parquet(\"../Data/Transport/Experian Registrations/Combined files for years/COUNTY_2014.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9ac6d0-317b-4699-8a4a-1467d568c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check14c.loc[(check14c[\"State Code\"]==37)&(check14c[\"County Code\"]==97), \"Vehicle Count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba31383-3031-4dce-8253-6b386b30f53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464482.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check14p.loc[(check14p[\"State Code\"]==37)&(check14p[\"County Code\"]==97), \"Vehicle Count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bac94a-b75c-4cc9-8cc1-5822b8b4e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.GEOID==37097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7c2d2-1540-4e4f-97c1-f92722560dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veh_reg = pd.read_parquet(\"../Data/Transport/Experian Registrations/sum_registrations.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4794d-98ba-470e-9cee-6c601da0823c",
   "metadata": {},
   "source": [
    "The Bipartisan Infrsatructure Act places a strong focus on equitable investment allocation. Equity can be explored both inter-regionally and intra-regionally by key demographic features. Figure 2 compares the distribution of charging stations for four representative cities. Omaha is located in the central Great Plains, a region that has received minimal exploration in the EV literature. Chicago and Detroit are large cities with well-documented histories of housing segregation (REF). San Francisco is included as an example of a large city in a progressive state. In all four cities, charging stations are concentrated in the central city. San Francisco does not show clear evidence of inequality, likely partially as a function of the overall high density of charging stations. However, Chicago and Detroit both show clear patterns of low charging station density in their majority-minority communities and unexpectedly high station densities in low density suburban communities. While there are few charging stations in Omamah, those outside its downtown are located along an east-west axis along the I-80 corridor. There are few stations in north and south Omaha, which are enclaves of black and hispanic residents, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ba4fb-f93b-4568-9051-26d330f1ee36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "df_pop_tr = pd.read_csv(\"../Data/Census/Population_Race_Tract/nhgis0008_ds248_2020_tract.csv\", encoding='latin-1')\n",
    "tract_sf = gpd.read_file(\"../Data/GIS/cb_2020_us_tract_500k/cb_2020_us_tract_500k.shp\")\n",
    "tract_sf = tract_sf.to_crs(4326)\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_ch_stn.Longitude, df_ch_stn.Latitude)]\n",
    "crs = 4326\n",
    "gdf_ch_stn = gpd.GeoDataFrame(df_ch_stn, crs=crs, geometry=geometry)\n",
    "\n",
    "df_pop_tr['GEOID'] = df_pop_tr['GEOID'].map(lambda x: x.lstrip('14000'))\n",
    "tract_sf['AFFGEOID'] = tract_sf['AFFGEOID'].map(lambda x: x.lstrip('1400000'))\n",
    "\n",
    "gdf_pop_tr = tract_sf.merge(df_pop_tr, left_on = 'AFFGEOID', right_on = 'GEOID', how = 'inner')\n",
    "gdf_pop_tr.loc[:,[\"STATEFP\",\"COUNTYFP\"]] = gdf_pop_tr.loc[:,[\"STATEFP\",\"COUNTYFP\"]].astype(int)\n",
    "# Minority is hispanic, black, native american, pacific islander, and some other race alone (do not include mixed race for simplicity)\n",
    "gdf_pop_tr['Minority_Percent'] = ((gdf_pop_tr['U7C002']+gdf_pop_tr['U7C006']+gdf_pop_tr['U7C007']+gdf_pop_tr['U7C009']+gdf_pop_tr['U7C010'])/gdf_pop_tr['U7C001'])*100\n",
    "gdf_pop_tr = gdf_pop_tr[~gdf_pop_tr.Minority_Percent.isnull()]\n",
    "\n",
    "norm = plt.Normalize(0, 100)\n",
    "\n",
    "# Plotting\n",
    "projection=gcrs.AlbersEqualArea(central_longitude=-98, central_latitude=39.5)\n",
    "fig, axs = plt.subplot_mosaic([[\"a)\",\"b)\"],[\"c)\",\"d)\"]], subplot_kw={'projection': projection}, figsize=(15, 12))\n",
    "fig.tight_layout()\n",
    "\n",
    "for label, ax in axs.items():\n",
    "    dfplot = gdf_ch_stn[(gdf_ch_stn['STATEFP'].isin(statefp)) & (gdf_ch_stn['COUNTYFP'].isin(countyfp))]\n",
    "    if label==\"a)\":\n",
    "        statefp = [31]\n",
    "        countyfp = [55]\n",
    "        size = 3\n",
    "        y_trans = 1.25\n",
    "        label = \" Omaha (N={0})\".format(dfplot[0])\n",
    "    elif label==\"b)\":\n",
    "        statefp = [17]\n",
    "        # countyfp = ['031', '043', '197']\n",
    "        countyfp = [31]\n",
    "        size = 2.7\n",
    "        y_trans=-20/72\n",
    "        label+=\" Chicago (N={0})\".format(dfplot[0])\n",
    "    elif label==\"c)\":\n",
    "        statefp = [6]\n",
    "        countyfp = [75, 81, 41, 1, 85]\n",
    "        size = 1.5\n",
    "        y_trans=5/72\n",
    "        label+=\" San Francisco (N={0})\".format(dfplot[0])\n",
    "    else:\n",
    "        statefp = [26]\n",
    "        countyfp = [163, 125, 99]\n",
    "        size = 3\n",
    "        y_trans=5/72\n",
    "        label+=\" Detroit (N={0})\".format(dfplot[0])\n",
    "        \n",
    "    gplt.choropleth(\n",
    "      gdf_pop_tr[(gdf_pop_tr['STATEFP'].isin(statefp)) & (gdf_pop_tr['COUNTYFP'].isin(countyfp))],\n",
    "      hue = \"Minority_Percent\",\n",
    "      # legend=True,\n",
    "      # legend_kwargs={'boundaries': (0,100,200,300,400)},\n",
    "      edgecolor='darkgrey',\n",
    "      linewidth=.5,\n",
    "      cmap=\"magma_r\",\n",
    "      norm = norm,\n",
    "      zorder = 1,\n",
    "      ax=ax\n",
    "    )\n",
    "\n",
    "    gplt.pointplot(\n",
    "      dfplot,\n",
    "      ax = ax,\n",
    "      color = 'white',\n",
    "      zorder = 2,\n",
    "      s = size,\n",
    "    )\n",
    "    trans = mtransforms.ScaledTranslation(10/72, y_trans, fig.dpi_scale_trans)\n",
    "    ax.text(0.0, 1.0, label, transform=ax.transAxes + trans,\n",
    "            fontsize='medium', verticalalignment='top', fontfamily='serif',\n",
    "            bbox=dict(facecolor='none', edgecolor='none', pad=3.0))\n",
    "\n",
    "# plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(ax4, cax=cax)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0.05, 0.80, 0.9, 0.1])\n",
    "\n",
    "# cb = mpl.colorbar.ColorbarBase(ax,\n",
    "#     orientation='horizontal', \n",
    "#     cmap='magma_r',\n",
    "#     norm = norm)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.8, 0.05, 0.05, 1.5])\n",
    "\n",
    "cb = mpl.colorbar.ColorbarBase(ax, \n",
    "    orientation='vertical', \n",
    "    cmap='viridis',\n",
    "    norm = norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467f429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def adf_test(df):\n",
    "    result = adfuller(df.values)\n",
    "    print('ADF Statistics: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "    \n",
    "def kpss_test(df):    \n",
    "    statistic, p_value, n_lags, critical_values = kpss(df.values)\n",
    "    \n",
    "    print(f'KPSS Statistic: {statistic}')\n",
    "    print(f'p-value: {p_value}')\n",
    "    print(f'num lags: {n_lags}')\n",
    "    print('Critial Values:')\n",
    "    for key, value in critical_values.items():\n",
    "        print(f'   {key} : {value}')\n",
    "        \n",
    "print('ADF Test: BEV time series')\n",
    "adf_test(us_tot['bev_cap'])\n",
    "print('ADF Test: cEVSE_cap time series')\n",
    "adf_test(us_tot['cEVSE_cap'])\n",
    "        \n",
    "print('KPSS Test: BEV time series')\n",
    "kpss_test(us_tot['bev_cap'])\n",
    "print('KPSS Test: cEVSE_cap time series')\n",
    "kpss_test(us_tot['cEVSE_cap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d8090",
   "metadata": {
    "tags": []
   },
   "source": [
    "Both ADF and KPSS tests indicate that the BEV and charging station data are non-stationary. Therefore, we will difference the data, as required by the Granger causality test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_tot_diff = us_tot.diff().dropna()\n",
    "print('ADF Test: BEV transformed time series')\n",
    "adf_test(us_tot_diff['bev_cap'])\n",
    "print('ADF Test: cEVSE_cap transformed time series')\n",
    "adf_test(us_tot_diff['cEVSE_cap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a66c7",
   "metadata": {},
   "source": [
    "The differences didn't help and we don't have a long enough time series to use a longer lag. Let's take a look at it by state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11621025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Neither time series is stationary for any state\n",
    "# state_list = pd.unique(df.STATE)\n",
    "# \n",
    "# for st in state_list:\n",
    "#   st_tot = df[df.STATE==st].groupby(\"year\").sum().reset_index()\n",
    "#   st_tot[\"bev_cap\"] = (st_tot[\"bev\"]/st_tot[\"ALUBE001\"])*100000\n",
    "#   st_tot[\"cEVSE_cap\"] = ((st_tot[\"cEVSE-L01\"]+st_tot[\"cEVSE-L02\"]+st_tot[\"cEVSE-L03\"])/st_tot[\"ALUBE001\"])*100000\n",
    "#   #print('ADF Test: BEV time series for {0}'.format(st))\n",
    "#   adf_test(st_tot['bev_cap']);\n",
    "#   #print('ADF Test: cEVSE_cap time series for {0}'.format(st))\n",
    "#   adf_test(st_tot['cEVSE_cap']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa90106",
   "metadata": {},
   "source": [
    "Let's try a non-linear causality analysis from Rosol et al.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a094f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from nonlincausality.nonlincausality import nonlincausalityMLP, nonlincausalityGRU, nonlincausalityLSTM, nonlincausalityNN, nonlincausalityARIMA\n",
    "# import itertools\n",
    "\n",
    "# def run_nonlin(data_train, data_test, max_lag):\n",
    "#     results = nonlincausalityMLP(x=data_train, maxlag=max_lag, Dense_layers=2, Dense_neurons=[100, 100], x_test=data_test, run=1, add_Dropout=True, Dropout_rate=0.01, epochs_num=[50, 100], learning_rate=[0.001, 0.0001], batch_size_num=128, verbose=False, plot=True)\n",
    "#     \n",
    "#     results_ARIMA = nonlincausalityARIMA(x=data_train, maxlag=max_lag, x_test=data_train)\n",
    "#     \n",
    "#     results_GRU = nonlincausalityGRU(x=data_train, maxlag=max_lag, GRU_layers=2, GRU_neurons=[25, 25], Dense_layers=2, Dense_neurons=[100, 100], x_test=data_test, run=3, add_Dropout=True, Dropout_rate=0.01, epochs_num=[50, 100], learning_rate=[0.001, 0.0001], batch_size_num=128, verbose=False, plot=True)\n",
    "#     \n",
    "#     results_LSTM = nonlincausalityLSTM(x=data_train, maxlag=max_lag, LSTM_layers=2, LSTM_neurons=[25, 25], Dense_layers=2, Dense_neurons=[100, 100], x_test=data_test, run=3, add_Dropout=True, Dropout_rate=0.01, epochs_num=[50, 100], learning_rate=[0.001, 0.0001], batch_size_num=128, verbose=False, plot=True)\n",
    "#     \n",
    "#     results_NN = nonlincausalityNN(x=data_train, maxlag=max_lag, NN_config=[\"l\", \"dr\", \"g\", \"dr\", \"d\", \"dr\"], NN_neurons=[5, 0.1, 5, 0.1, 5, 0.1], x_test=data_test, run=3, epochs_num=[50, 100], learning_rate=[0.001, 0.0001], batch_size_num=128, verbose=False, plot=True)\n",
    "#     \n",
    "#     #%% Example of obtaining the results\n",
    "#     lags = [1,2,3,4,5]\n",
    "#     models = [\"MLP\",\"ARIMA\",\"GRU\",\"LSTM\",\"NN\"]\n",
    "#     index = pd.MultiIndex.from_tuples(list(itertools.product(models, lags)), names=[\"model\", \"lag\"])\n",
    "#     granger_df = pd.DataFrame(index=index,columns=[\"cohens_d\",\"test_stat\",\"p_value\"])\n",
    "#     \n",
    "#     for name, res in {\"MLP\":results, \"ARIMA\":results_ARIMA, \"GRU\":results_GRU, \"LSTM\":results_LSTM, \"NN\":results_NN}.items():\n",
    "#     \n",
    "#         for lag in lags:\n",
    "#             p_value = res[lag].p_value\n",
    "#             test_stat = res[lag].test_statistic\n",
    "#     \n",
    "#             best_errors_X = res[lag].best_errors_X\n",
    "#             best_errors_XY = res[lag].best_errors_XY\n",
    "#     \n",
    "#             cohens_d = np.abs(\n",
    "#                 (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "#                 / np.std([best_errors_X, best_errors_XY])\n",
    "#             )\n",
    "#             print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "#             print(f\"test statistic = {0} p-value = {1}\".format(test_stat,p_value))\n",
    "#             granger_df.loc[(name,lag),\"cohens_d\"] = cohens_d\n",
    "#             granger_df.loc[(name,lag),\"test_stat\"] = test_stat\n",
    "#             granger_df.loc[(name,lag),\"p_value\"] = p_value\n",
    "#     return granger_df\n",
    "# \n",
    "# lag = 5 # number of years\n",
    "# \n",
    "# cty_list = pd.unique(df.GEOID)\n",
    "# train_cty, test_cty = np.split(cty_list, [int(len(cty_list)*0.7)])\n",
    "# data_train = df.loc[df.GEOID.isin(train_cty),[\"pev_cap\",\"cEVSE_cap\"]].values\n",
    "# data_test = df.loc[df.GEOID.isin(test_cty),[\"pev_cap\",\"cEVSE_cap\"]].values\n",
    "# \n",
    "# # Run assuming PEV registrations cause charging station installations\n",
    "# run_nonlin(data_train,data_test,lag).to_csv(\"granger_df_pev_ch.csv\")\n",
    "# \n",
    "# data_train = df.loc[df.GEOID.isin(train_cty),[\"cEVSE_cap\",\"pev_cap\"]].values\n",
    "# data_test = df.loc[df.GEOID.isin(test_cty),[\"cEVSE_cap\",\"pev_cap\"]].values\n",
    "# \n",
    "# # Run assuming PEV registrations cause charging station installations\n",
    "# run_nonlin(data_train,data_test,lag).to_csv(\"granger_df_ch_pev.csv\")\n",
    "# \n",
    "# data_train = df.loc[df.GEOID.isin(train_cty),[\"cEVSE_cap_lag\",\"pev_cap\"]].values\n",
    "# data_test = df.loc[df.GEOID.isin(test_cty),[\"cEVSE_cap_lag\",\"pev_cap\"]].values\n",
    "# \n",
    "# # Run assuming PEV registrations cause charging station installations - using lagged data\n",
    "# run_nonlin(data_train,data_test,lag).to_csv(\"granger_df_ch_pev_lag.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb6e12-2296-4241-83c4-5aa50febc26a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Another simple descriptive comparison between the PEV and charging station markets is shown in Figure 3. PEV sales market share is plotted against charging stations per thousand residents as of 2020. While there appears to be a positive correlation between these infrastructures, there are clearly other factors at play - e.g., observe the difference between California and Vermont. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb19f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO DO: Add more state labels\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "timeseriesx = []\n",
    "timeseriesy = []\n",
    "\n",
    "merged_df = pd.DataFrame(geo_ch_stn)\n",
    "merged_df['Open Date'] = pd.to_datetime(merged_df['Open Date'])\n",
    "yearpop = 2019\n",
    "year = 2020\n",
    "\n",
    "merged_year = merged_df.loc[merged_df['Open Date'] < datetime.datetime(yearpop,12,31)]\n",
    "\n",
    "num_stations_by_state = merged_year['State'].value_counts()\n",
    "\n",
    "num_stations_by_state = pd.DataFrame(num_stations_by_state)\n",
    "num_stations_by_state = num_stations_by_state.reset_index()\n",
    "num_stations_by_state.columns = ['State','Charging Stations']\n",
    "\n",
    "drop = [\"PR\", \"ON\"]\n",
    "\n",
    "num_stations_by_state = num_stations_by_state[num_stations_by_state.State.isin(drop) == False]\n",
    "\n",
    "ev_market_share = pd.read_csv(\"../Data/Transport/BEV-PHEV-HEV-FCEV-ICE-Sales-By State-2011-2020-EVAdoption-7.13.21.csv\")\n",
    "\n",
    "stations_vs_marketshare = pd.merge(df_pop, num_stations_by_state, left_on= \"State\", right_on=\"State\", how = \"right\")\n",
    "stations_vs_marketshare = pd.merge(stations_vs_marketshare, ev_market_share, left_on= \"Geographic Area\", right_on=\"State\", how = \"left\")\n",
    "\n",
    "stations_vs_marketshare['Stations Per Capita'] = (stations_vs_marketshare['Charging Stations']/stations_vs_marketshare[str(yearpop)])*1000\n",
    "stations_vs_marketshare['EV (BEV & PHEV) Share'] = stations_vs_marketshare['EV (BEV & PHEV) Share']*100\n",
    "\n",
    "share_v_stations_plot = sns.scatterplot(\n",
    "    data = stations_vs_marketshare,\n",
    "    x=\"Stations Per Capita\", y=\"EV (BEV & PHEV) Share\",\n",
    ")\n",
    "share_v_stations_plot.set_xlabel(\"Charging Stations per Capita\")\n",
    "share_v_stations_plot.set_ylabel(\"BEV+PHEV Market Share (%)\")\n",
    "share_v_stations_plot.set(xlim=(0, 0.4))\n",
    "share_v_stations_plot.set(ylim=(0, 10))\n",
    "\n",
    "\n",
    "# Just for fun\n",
    "state_labels = [\"California\", \"Vermont\", \"Florida\"]\n",
    "i = 0\n",
    "# for state in stations_vs_marketshare['Geographic Area']:\n",
    "for state in state_labels:\n",
    "    x = stations_vs_marketshare.loc[stations_vs_marketshare['Geographic Area'] == state, 'Stations Per Capita'].iloc[0]\n",
    "    y = stations_vs_marketshare.loc[stations_vs_marketshare['Geographic Area'] == state, 'EV (BEV & PHEV) Share'].iloc[0]\n",
    "    share_v_stations_plot.text(x + 0.005, y - 0.001 , state)\n",
    "    timeseriesx.append([])\n",
    "    timeseriesy.append([])\n",
    "    timeseriesx[i].append(x)\n",
    "    timeseriesy[i].append(y)\n",
    "\n",
    "    i = i + 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732b532-637b-4823-8246-40184db5e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_vs_marketshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77968512-ca39-4a18-986c-96824bb92987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the Granger causality results and create a table from it\n",
    "df_gr_pev_ch = pd.read_csv(\"granger_df_pev_ch.csv\")\n",
    "df_gr_ch_pev = pd.read_csv(\"granger_df_ch_pev.csv\")\n",
    "df_gr_ch_pev_lag = pd.read_csv(\"granger_df_ch_pev_lag.csv\")\n",
    "df_gr_pev_ch_lag = pd.read_csv(\"granger_df_pev_ch_lag.csv\")\n",
    "df1 = df_gr_pev_ch.merge(df_gr_ch_pev,how=\"left\",on=[\"model\",\"lag\"],suffixes=(\"_pc\",\"_cp\"))\n",
    "df2 = df_gr_ch_pev_lag.merge(df_gr_pev_ch_lag,how=\"left\",on=[\"model\",\"lag\"],suffixes=(\"_pcl\",\"_cpl\"))\n",
    "df1 = df1.merge(df2,how=\"left\",on=[\"model\",\"lag\"])\n",
    "# Filter out columns where none of the cohens_d are significant\n",
    "df1 = df1[(df1.p_value_pc<0.05) | (df1.p_value_cp<0.05) | (df1.p_value_pcl<0.05) | (df1.p_value_cpl<0.05)]\n",
    "\n",
    "# Style the table\n",
    "def bold_sig(v, p_val_col = \"\", props='', threshold=0.05):\n",
    "    if p_val_col not in df1:\n",
    "        return np.full(v.shape, \"\")\n",
    "    return np.where(df1[p_val_col].le(threshold), props, \"\")\n",
    "\n",
    "df1.sort_values(by=[\"model\",\"lag\"],inplace=True)\n",
    "df1.style.apply(bold_sig, p_val_col=\"p_value_pc\", props=\"font-weight: bold;\", subset=( \"cohens_d_pc\"), axis=0, threshold=0.05) \\\n",
    ".apply(bold_sig, p_val_col=\"p_value_cp\", props=\"font-weight: bold;\", subset=( \"cohens_d_cp\"), axis=0, threshold=0.05) \\\n",
    ".apply(bold_sig, p_val_col=\"p_value_pcl\", props=\"font-weight: bold;\", subset=( \"cohens_d_pcl\"), axis=0, threshold=0.05) \\\n",
    ".apply(bold_sig, p_val_col=\"p_value_cpl\", props=\"font-weight: bold;\", subset=( \"cohens_d_cpl\"), axis=0, threshold=0.05) \\\n",
    ".hide(subset=[\"p_value_pc\",\"p_value_cp\",\"p_value_pcl\",\"p_value_cpl\"], axis=\"columns\") \\\n",
    ".hide(axis=\"index\").format(precision=3) \\\n",
    ".highlight_max(subset=[\"cohens_d_pc\",\"cohens_d_cp\",\"cohens_d_pcl\",\"cohens_d_cpl\"], color='grey', axis=0, props=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30bb22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_curve import GPS_Regressor\n",
    "gps = GPS_Regressor(verbose=True)\n",
    "T = gdf['cEVSE_cap']\n",
    "y = gdf['pev_cap']\n",
    "X = pd.concat([gdf.xW,gdf.filter(like=\"st_\",axis=1)],axis=1)\n",
    "\n",
    "gps.fit(T=T, X = X, y=y)\n",
    "gps_results = gps.calculate_CDRC(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43292b46-66c9-4465-ba21-e5799c0d4f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_mean_and_CI(ax, treatment, mean, lb, ub, color_mean=None, color_shading=None):\n",
    "    # plot the shaded range of the confidence intervals\n",
    "    ax.fill_between(treatment, lb, ub, color=color_shading, alpha=0.3)\n",
    "    # plot the mean on top\n",
    "    ax.plot(treatment, mean, color_mean, linewidth=0.75)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "    \n",
    "treat = gps_results['Treatment']\n",
    "mean = gps_results['Causal_Dose_Response']\n",
    "lb = gps_results['Lower_CI']\n",
    "ub = gps_results['Upper_CI']\n",
    "plot_mean_and_CI(ax, treat, mean, lb, ub, color_mean='b', color_shading='b')\n",
    "\n",
    "# Labels\n",
    "ax.set_ylabel('PEVs per 100,000 ', fontsize = 8)\n",
    "ax.set_xlabel('Charging stations per 100,000', fontsize = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2dc57-f602-4494-bbfc-58d5cad595c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gam = gps.gam_results\n",
    "for i, term in enumerate(gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    pdep, confi = gam.partial_dependence(term=i, X=XX, width=0.95)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(XX[:, term.feature], pdep)\n",
    "    plt.plot(XX[:, term.feature], confi, c='r', ls='--')\n",
    "    plt.title(repr(term))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c49e9d-a8c6-4edd-8547-40a0676f958b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO DO: filter out FE and show them in a figure with error bars\n",
    "mr = gps.gps_results\n",
    "df_mod = pd.concat([mr.params,mr.tvalues],axis=1)\n",
    "df_mod.columns = [\"est.\",\"t-stat\"]\n",
    "filt_idx = list(df_mod[df_mod.index.str.contains(\"st_\")].index)\n",
    "df_mod.style.hide(subset=filt_idx, axis=\"index\").format({'est.': \"{:.2}\",\"t-stat\":\"{:.2f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3c5ec-390a-480b-9678-f85434b983d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create a plot of state fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f55d1c",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "# Conclusions\n",
    "\n",
    "The results presented herein are preliminary and do not consider a key dataset -- vehicle registrations. We will expand our analysis to a more robust inferential study in the coming months. Our causal question is what effect public charging stations have on electric vehicle registrations at the county-level. The treatment variable is continuous over the study period. We propose three causal identification approaches. The first approach is a difference-in-differences approach that is identified off state-level investments in charging stations by year. The second approach is generalized propensity score matching using federal election results, state-level greenhouse gas (GHG) emissions factors, and demographic characteristics (e.g., racial composition, median income, and population density) as inputs to the propensity score.\n",
    "\n",
    "The final causal inference approach, Granger causality, differs in that it focuses on the temporal phasing of charging station installations and PEV registration, whereas the other two approaches rely on Rubin's potential outcome assumption [@reich2021]. Granger causality relies on the assumption that past treatment knowledge reduces predictive uncertainty. It is a form of time series causal inference that would fit the current context well.\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo_env]",
   "language": "python",
   "name": "conda-env-geo_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
